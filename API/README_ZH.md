# DeepAnalyze API æœåŠ¡å™¨

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å‰ç½®æ¡ä»¶

**å¯åŠ¨ vLLM æ¨¡å‹æœåŠ¡å™¨**:

```bash
vllm serve DeepAnalyze-8B --host 0.0.0.0 --port 8000
```

### å¯åŠ¨æœåŠ¡å™¨

```bash
cd API
python start_server.py
```

- **API æœåŠ¡å™¨**: `http://localhost:8200` (ä¸» API)
- **æ–‡ä»¶æœåŠ¡å™¨**: `http://localhost:8100` (æ–‡ä»¶ä¸‹è½½)
- **å¥åº·æ£€æŸ¥**: `http://localhost:8200/health`

API æœåŠ¡å™¨å°†åœ¨å½“å‰ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªæ–°çš„ `workspace` æ–‡ä»¶å¤¹ä½œä¸ºå·¥ä½œç›®å½•ã€‚å¯¹äºæ¯ä¸ªå¯¹è¯ï¼Œå®ƒå°†åœ¨è¯¥å·¥ä½œç©ºé—´ä¸‹ç”Ÿæˆä¸€ä¸ª `thread` å­ç›®å½•æ¥æ‰§è¡Œæ•°æ®åˆ†æå¹¶ç”Ÿæˆæ–‡ä»¶ã€‚

### å¿«é€Ÿæµ‹è¯•

```bash
cd example
python exampleRequest.py          # è¯·æ±‚ç¤ºä¾‹
python exampleOpenAI.py    # OpenAI åº“ç¤ºä¾‹
```

## ğŸ“š API ä½¿ç”¨

### 1. æ–‡ä»¶ä¸Šä¼ 

**è¯·æ±‚ç¤ºä¾‹:**
```python
import requests

with open('data.csv', 'rb') as f:
    files = {'file': ('data.csv', f, 'text/csv')}
    response = requests.post('http://localhost:8200/v1/files', files=files)

file_id = response.json()['id']
print(f"File uploaded: {file_id}")
```

**OpenAI åº“ç¤ºä¾‹:**
```python
import openai

client = openai.OpenAI(
    base_url="http://localhost:8200/v1",
    api_key="dummy"
)

with open('data.csv', 'rb') as f:
    file_obj = client.files.create(file=f)

print(f"File uploaded: {file_obj.id}")
```

### 2. ç®€å•èŠå¤©ï¼ˆæ— æ–‡ä»¶ï¼‰

**è¯·æ±‚ç¤ºä¾‹:**

```python
response = requests.post('http://localhost:8200/v1/chat/completions', json={
    "model": "DeepAnalyze-8B",
    "messages": [
        {"role": "user", "content": "ç”¨ä¸€å¥è¯ä»‹ç»Pythonç¼–ç¨‹è¯­è¨€"}
    ],
    "temperature": 0.4
})

content = response.json()['choices'][0]['message']['content']
print(content)
```

**OpenAI åº“ç¤ºä¾‹:**
```python
response = client.chat.completions.create(
    model="DeepAnalyze-8B",
    messages=[
        {"role": "user", "content": "ç”¨ä¸€å¥è¯ä»‹ç»Pythonç¼–ç¨‹è¯­è¨€"}
    ],
    temperature=0.4
)

print(response.choices[0].message.content)
```

### 3. å¸¦æ–‡ä»¶çš„èŠå¤©

**è¯·æ±‚ç¤ºä¾‹:**
```python
response = requests.post('http://localhost:8200/v1/chat/completions', json={
    "model": "DeepAnalyze-8B",
    "messages": [
        {
            "role": "user",
            "content": "åˆ†æè¿™ä¸ªæ•°æ®æ–‡ä»¶ï¼Œè®¡ç®—å„éƒ¨é—¨çš„å¹³å‡è–ªèµ„ï¼Œå¹¶ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ã€‚",
            "file_ids": [file_id]
        }
    ],
    "temperature": 0.4
})

result = response.json()
content = result['choices'][0]['message']['content']
files = result['choices'][0]['message'].get('files', [])

print(f"Response: {content}")
for file_info in files:
    print(f"Generated file: {file_info['name']} - {file_info['url']}")
```

**OpenAI åº“ç¤ºä¾‹:**
```python
response = client.chat.completions.create(
    model="DeepAnalyze-8B",
    messages=[
        {
            "role": "user",
            "content": "åˆ†æè¿™ä¸ªæ•°æ®æ–‡ä»¶ï¼Œè®¡ç®—å„éƒ¨é—¨çš„å¹³å‡è–ªèµ„ï¼Œå¹¶ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ã€‚",
            "file_ids": [file_id]
        }
    ],
    temperature=0.4
)

message = response.choices[0].message
print(f"Response: {message.content}")

# Access generated files (new format)
if hasattr(message, 'files') and message.files:
    for file_info in message.files:
        print(f"Generated file: {file_info['name']} - {file_info['url']}")
```

### 4. æµå¼èŠå¤©ä¸æ–‡ä»¶

**è¯·æ±‚ç¤ºä¾‹:**

```python
response = requests.post('http://localhost:8200/v1/chat/completions', json={
    "model": "DeepAnalyze-8B",
    "messages": [
        {
            "role": "user",
            "content": "åˆ†æè¿™ä¸ªæ•°æ®å¹¶ç”Ÿæˆè¶‹åŠ¿å›¾ã€‚",
            "file_ids": [file_id]
        }
    ],
    "stream": True
}, stream=True)

for line in response.iter_lines():
    if line:
        line_str = line.decode('utf-8')
        if line_str.startswith('data: '):
            data_str = line_str[6:]
            if data_str == '[DONE]':
                break
            chunk = json.loads(data_str)
            if 'choices' in chunk and chunk['choices']:
                delta = chunk['choices'][0].get('delta', {})
                if 'content' in delta:
                    print(delta['content'], end='', flush=True)
```

**OpenAI åº“ç¤ºä¾‹:**
```python
stream = client.chat.completions.create(
    model="DeepAnalyze-8B",
    messages=[
        {
            "role": "user",
            "content": "åˆ†æè¿™ä¸ªæ•°æ®å¹¶ç”Ÿæˆè¶‹åŠ¿å›¾ã€‚",
            "file_ids": [file_id]
        }
    ],
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end='', flush=True)
    if hasattr(chunk, 'generated_files') and chunk.generated_files:
        collected_files.extend(chunk.generated_files)
```




## ğŸ“‹ API å‚è€ƒ

### æ–‡ä»¶ API

#### POST /v1/files
ä¸Šä¼ æ–‡ä»¶è¿›è¡Œåˆ†æã€‚

**è¯·æ±‚:**
```http
POST /v1/files
Content-Type: multipart/form-data

file: [binary file data]
```

**å“åº”:**
```json
{
  "id": "file-abc123...",
  "object": "file",
  "bytes": 1024,
  "created_at": 1704067200,
  "filename": "data.csv"
}
```

#### GET /v1/files
åˆ—å‡ºæ‰€æœ‰ä¸Šä¼ çš„æ–‡ä»¶ã€‚

**è¯·æ±‚:**
```http
GET /v1/files
```

**å“åº”:**
```json
{
  "object": "list",
  "data": [
    {
      "id": "file-abc123...",
      "object": "file",
      "bytes": 1024,
      "created_at": 1704067200,
      "filename": "data.csv"
    }
  ]
}
```

#### GET /v1/files/{file_id}/content
ä¸‹è½½æ–‡ä»¶å†…å®¹ã€‚

**è¯·æ±‚:**
```http
GET /v1/files/{file_id}/content
```

**å“åº”:** äºŒè¿›åˆ¶æ–‡ä»¶å†…å®¹

#### DELETE /v1/files/{file_id}
åˆ é™¤æ–‡ä»¶ã€‚

**è¯·æ±‚:**
```http
DELETE /v1/files/{file_id}
```

**å“åº”:**
```json
{
  "id": "file-abc123...",
  "object": "file",
  "deleted": true
}
```

### èŠå¤©å®Œæˆ API

#### POST /v1/chat/completions
æ‰©å±•èŠå¤©å®Œæˆï¼Œæ”¯æŒæ–‡ä»¶åŠŸèƒ½ã€‚

**è¯·æ±‚:**
```json
{
  "model": "DeepAnalyze-8B",
  "messages": [
    {
      "role": "user",
      "content": "åˆ†æè¿™ä¸ªæ•°æ®æ–‡ä»¶",
      "file_ids": ["file-abc123"]  // OpenAI å…¼å®¹ï¼šæ¶ˆæ¯ä¸­çš„ file_ids
    }
  ],
  "file_ids": ["file-def456"],     // å¯é€‰ï¼šfile_ids å‚æ•°
  "temperature": 0.4,
  "stream": false
}
```

**å“åº”ï¼ˆéæµå¼ï¼‰:**
```json
{
  "id": "chatcmpl-xyz789...",
  "object": "chat.completion",
  "created": 1704067200,
  "model": "DeepAnalyze-8B",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "åˆ†æç»“æœ...",
        "files": [                    //æ¶ˆæ¯ä¸­çš„æ–‡ä»¶
          {
            "name": "chart.png",
            "url": "http://localhost:8100/thread-123/generated/chart.png"
          }
        ]
      },
      "finish_reason": "stop"
    }
  ],
  "generated_files": [              // generated_files å­—æ®µ
    {
      "name": "chart.png",
      "url": "http://localhost:8100/thread-123/generated/chart.png"
    }
  ],
  "attached_files": ["file-abc123"] // è¾“å…¥æ–‡ä»¶
}
```

**å“åº”ï¼ˆæµå¼ï¼‰:**
```
data: {"id": "chatcmpl-xyz789...", "object": "chat.completion.chunk", "choices": [{"delta": {"content": "åˆ†æ"}}]}
data: {"id": "chatcmpl-xyz789...", "object": "chat.completion.chunk", "choices": [{"delta": {"files": [{"name":"chart.png","url":"..."}]}, "finish_reason": "stop"}]}
data: [DONE]
```




### å¥åº·æ£€æŸ¥ API

#### GET /health
æ£€æŸ¥ API æœåŠ¡å™¨çŠ¶æ€ã€‚

**è¯·æ±‚:**
```http
GET /health
```

**å“åº”:**
```json
{
  "status": "healthy",
  "timestamp": 1704067200
}
```

## ğŸ—ï¸ æ¶æ„

### å¤šç«¯å£è®¾è®¡

- **ç«¯å£ 8000**: vLLM æ¨¡å‹æœåŠ¡å™¨ï¼ˆå¤–éƒ¨ï¼‰
- **ç«¯å£ 8200**: ä¸» API æœåŠ¡å™¨ï¼ˆFastAPIï¼‰
- **ç«¯å£ 8100**: æ–‡ä»¶ HTTP æœåŠ¡å™¨ç”¨äºä¸‹è½½

## ğŸ”§ é…ç½®

### ç¯å¢ƒå˜é‡

```python
# API é…ç½®
API_BASE = "http://localhost:8000/v1"  # vLLM ç«¯ç‚¹
MODEL_PATH = "DeepAnalyze-8B"          # æ¨¡å‹åç§°
WORKSPACE_BASE_DIR = "workspace"       # æ–‡ä»¶å­˜å‚¨
HTTP_SERVER_PORT = 8100               # æ–‡ä»¶æœåŠ¡å™¨ç«¯å£

# æ¨¡å‹è®¾ç½®
DEFAULT_TEMPERATURE = 0.4            # é»˜è®¤é‡‡æ ·æ¸©åº¦
MAX_NEW_TOKENS = 32768               # æœ€å¤§å“åº”ä»¤ç‰Œæ•°
STOP_TOKEN_IDS = [32000, 32007]      # ç‰¹æ®Šä»¤ç‰Œ ID
```



## ğŸ› ï¸ ç¤ºä¾‹

`example/` ç›®å½•åŒ…å«å…¨é¢çš„ç¤ºä¾‹ï¼š

- `example.py` - ç®€å•è¯·æ±‚ç¤ºä¾‹
- `exampleOpenAI.py` - OpenAI åº“ç¤ºä¾‹