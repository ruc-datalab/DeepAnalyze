"""
Example usage of DeepAnalyze OpenAI-Compatible API with OpenAI library
Demonstrates 2-turn data analysis workflow with file attachments and streaming
"""

import openai
import time
import re
from pathlib import Path

# Configure OpenAI client for DeepAnalyze
API_BASE = "http://localhost:8200/v1"
MODEL = "DeepAnalyze-8B"

client = openai.OpenAI(
    base_url=API_BASE,
    api_key="dummy"  # DeepAnalyze doesn't require a real API key
)

def file_api_examples():
    """Demonstrate various file API operations"""
    try:
        # Create test file
        test_file_path = Path("test.txt")
        test_file_path.write_text("Test content")

        # Create files with different purposes
        file1 = client.files.create(file=test_file_path, purpose="file-extract")
        file2 = client.files.create(file=test_file_path, purpose="file-extract")

        print(f"Created files: {file1.id} (extract), {file2.id} (assistants)")

        # List files
        files_list = client.files.list()
        print(f"Total files: {len(files_list.data)}")

        # Get content (file-extract purpose)
        if file1.purpose == "file-extract":
            content = client.files.content(file1.id)
            print(f"File content: {content.text}")

        # Cleanup
        client.files.delete(file1.id)
        client.files.delete(file2.id)
        test_file_path.unlink()
        print("âœ… File API examples completed")

    except Exception as e:
        print(f"âŒ Error: {e}")


def chat_completion_with_message_file_ids():
    """Chat completion with file_ids in messages (OpenAI compatibility)"""
    try:
        # Use existing Simpson.csv file
        with open("./Simpson.csv", "rb") as f:
            file_obj = client.files.create(file=f, purpose="file-extract")

        # New format: file_ids in messages
        messages = [
            {
                "role": "user",
                "content": "åˆ†ææ•°æ®ï¼Œæ€»ç»“ä¸»è¦å‘ç°ã€‚",
                "file_ids": [file_obj.id]
            }
        ]

        response = client.chat.completions.create(model=MODEL, messages=messages)
        message = response.choices[0].message

        print(f"Response: {message.content}")

        # Check for thread_id using hasattr()
        if hasattr(message, 'thread_id'):
            print(f"Thread ID: {message.thread_id}")

        # Show files from both formats
        if hasattr(message, 'files') and message.files:
            print(f"Files (message): {len(message.files)}")
        if hasattr(response, 'generated_files') and response.generated_files:
            print(f"Files (response): {len(response.generated_files)}")
        for file in response.generated_files:
            print(f"- {file['name']}: {file['url']}")


    except Exception as e:
        print(f"âŒ Error: {e}")


def multi_turn_example():
    """Demonstrate 2-turn thread_id workflow with OpenAI library using streaming and file attachments"""
    try:
        messages = []

        # Upload data file
        print("ğŸ“ Uploading Simpson.csv data file...")
        with open("./Simpson.csv", "rb") as f:
            file_obj = client.files.create(file=f, purpose="file-extract")
        print(f"âœ… File uploaded successfully: {file_obj.id[:12]}...")

        # First request - creates new thread, examine data structure
        print("1ï¸âƒ£ First request - examining data structure...")
        messages.append({
            "role": "user",
            "content": "è¯·æŸ¥çœ‹è¿™ä¸ªæ•°æ®æ–‡ä»¶çš„ç»“æ„ï¼Œå‘Šè¯‰æˆ‘æœ‰å“ªäº›å­—æ®µã€æ•°æ®ç±»å‹å’ŒåŸºæœ¬ç»Ÿè®¡ä¿¡æ¯ã€‚",
            "file_ids": [file_obj.id]
        })

        print("Streaming response...")
        stream = client.chat.completions.create(
            model=MODEL,
            messages=messages,
            stream=True
        )

        full_response = ""
        received_thread_id = None
        collected_files = []

        for chunk in stream:
            if chunk.choices and chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                print(content, end='', flush=True)
                full_response += content

            # Check for thread_id in streaming chunks
            if hasattr(chunk.choices[0].delta, 'thread_id') and chunk.choices[0].delta.thread_id:
                received_thread_id = chunk.choices[0].delta.thread_id

            # Collect files from chunks
            if hasattr(chunk, 'generated_files') and chunk.generated_files:
                collected_files.extend(chunk.generated_files)

        print()  # New line after streaming
        thread_id = received_thread_id
        print(f"ğŸ“ Response received with thread_id: {thread_id}")

        if collected_files:
            print(f"ğŸ“ Files generated: {len(collected_files)}")

        messages.append({"role": "assistant", "content": full_response})

        # Second request with thread_id - generate analysis report
        print(f"\n2ï¸âƒ£ Second request - generating analysis report (with thread_id: {thread_id[:12] if thread_id else 'None'}...)...")
        messages.append({
            "role": "user",
            "content": "åŸºäºåˆšæ‰çš„æ•°æ®ç»“æ„åˆ†æï¼Œè¯·ç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„æ•°æ®åˆ†ææŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š\n1. æ•°æ®è´¨é‡è¯„ä¼°\n2. å„å­—æ®µçš„æ•°æ®åˆ†å¸ƒ\n3. ç›¸å…³æ€§åˆ†æ\n4. ä¸»è¦å‘ç°å’Œæ´å¯Ÿ",
            "file_ids": [file_obj.id]
        })
        if thread_id:
            messages[-1]["thread_id"] = thread_id

        print("Streaming response...")
        stream = client.chat.completions.create(
            model=MODEL,
            messages=messages,
            stream=True
        )

        full_response2 = ""
        returned_thread_id = None
        collected_files2 = []

        for chunk in stream:
            if chunk.choices and chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                print(content, end='', flush=True)
                full_response2 += content

            # Check for thread_id in streaming chunks
            if hasattr(chunk.choices[0].delta, 'thread_id') and chunk.choices[0].delta.thread_id:
                returned_thread_id = chunk.choices[0].delta.thread_id

            # Collect files from chunks
            if hasattr(chunk, 'generated_files') and chunk.generated_files:
                collected_files2.extend(chunk.generated_files)

        print()  # New line after streaming
        print(f"ğŸ“ Response thread_id: {returned_thread_id[:12] if returned_thread_id else 'None'}...")
        print(f"âœ… Thread ID match: {thread_id == returned_thread_id}")

        if collected_files2:
            print(f"ğŸ“ Files generated: {len(collected_files2)}")

        # Cleanup uploaded file
        client.files.delete(file_obj.id)
        print("ğŸ—‘ï¸  Uploaded file cleaned up")

        print("\nâœ… 2-turn data analysis workflow completed!")

    except Exception as e:
        print(f"âŒ Error: {e}")


def streaming_chat_completion_with_files():
    """Streaming chat completion with file handling"""
    try:
        # Use existing Simpson.csv file
        with open("./Simpson.csv", "rb") as f:
            file_obj = client.files.create(file=f, purpose="file-extract")

        # Streaming with file_ids in messages
        messages = [
            {
                "role": "user",
                "content": "åˆ†ææ•°æ®å¹¶ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ã€‚",
                "file_ids": [file_obj.id]
            }
        ]

        print("Streaming...")
        stream = client.chat.completions.create(
            model=MODEL,
            messages=messages,
            stream=True
        )

        full_response = ""
        collected_files = []
        received_thread_id = None

        for chunk in stream:
            if chunk.choices and chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                print(content, end='', flush=True)
                full_response += content

            # Check for thread_id in streaming chunks
            if hasattr(chunk.choices[0].delta, 'thread_id') and chunk.choices[0].delta.thread_id:
                received_thread_id = chunk.choices[0].delta.thread_id

            # Collect files from chunks
            if hasattr(chunk, 'generated_files') and chunk.generated_files:
                collected_files.extend(chunk.generated_files)

        if received_thread_id:
            print(f"\nThread ID: {received_thread_id}")

        print(f"\nâœ… Streaming complete ({len(full_response)} chars, {len(collected_files)} files)")
        for file in collected_files:
            print(f"- {file['name']}: {file['url']}")

    except Exception as e:
        print(f"âŒ Error: {e}")






def main():
    """Interactive example selector"""
    print("ğŸš€ DeepAnalyze API Examples")
    print("API: localhost:8200 | Model: localhost:8000\n")

    examples = {
        "1": ("File API", file_api_examples),
        "2": ("Chat Completion", chat_completion_with_message_file_ids),
        "3": ("2-Turn Data Analysis", multi_turn_example),
        "4": ("Streaming", streaming_chat_completion_with_files),
        "5": ("All Examples", None)
    }

    while True:
        print("ğŸ“‹ Examples:")
        for num, (name, _) in examples.items():
            print(f"{num}. {name}")
        print("0. Exit")

        choice = input("\nSelect (0-5): ").strip()

        if choice == "0":
            print("ğŸ‘‹ Goodbye!")
            break

        if choice not in examples:
            print("âŒ Invalid choice")
            continue

        try:
            # Test connection
            models = client.models.list()
            print(f"âœ… Connected: {[m.id for m in models.data]}")

            if choice == "5":  # Run all examples
                for num, (name, func) in list(examples.items())[:-1]:
                    print(f"\n{name}:")
                    func()
            else:
                name, func = examples[choice]
                print(f"\n{name}:")
                func()

        except KeyboardInterrupt:
            print("\nğŸ‘‹ Goodbye!")
            break
        except Exception as e:
            print(f"âŒ Error: {e}")
            print("Ensure API server (localhost:8200) and model server (localhost:8000) are running")
            if choice in ["2", "3", "4", "5"]:
                print("And Simpson.csv exists in current directory")


if __name__ == "__main__":
    main()