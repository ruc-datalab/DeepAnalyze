# Docker Compose configuration for DeepAnalyze with API and File Server
# Usage: docker-compose up -d
# This configuration starts:
# - vLLM server on port 8000
# - API server on port 8200
# - File server on port 8100

version: '3.8'

services:
  deepanalyze:
    # Use pre-built image from Docker Hub or locally built image
    image: deepanalyze-env-with-api:latest
    # Or pull from Docker Hub:
    # image: yourusername/deepanalyze-env-with-api:latest

    container_name: deepanalyze-full-stack

    # GPU support
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    # Port mapping for all services
    ports:
      - "8000:8000"  # vLLM API
      - "8100:8100"  # File Server
      - "8200:8200"  # API Server

    # Volume mounts
    volumes:
      - ./workspace:/workspace/API/workspace
      - ./models:/models

    # Environment variables (optional)
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - API_HOST=0.0.0.0
      - API_PORT=8200
      - HTTP_SERVER_PORT=8100
      - API_BASE=http://localhost:8000/v1
      - MODEL_PATH=DeepAnalyze-8B
      # - VLLM_USE_MODELSCOPE=False

    # Use the startup script to launch all services
    # The container will automatically start vLLM, API server, and file server
    command: /workspace/start_services.sh

    # Keep container running and restart on failure
    restart: unless-stopped
