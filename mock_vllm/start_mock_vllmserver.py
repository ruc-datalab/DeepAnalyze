import http.server
import json
import time
from typing import Dict, Any

# åŸå§‹å®Œæ•´å›å¤æ–‡æœ¬ï¼ˆä¸å†æŒ‰è¡Œæ‹†åˆ†ï¼Œåç»­é€å­—å¤„ç†ï¼‰
FULL_RESPONSE_TEXT = """æˆ‘æ­£åœ¨åˆ†ææ‚¨æä¾›çš„æ•°æ®...

ä»æ•°æ®ä¸­å¯ä»¥è§‚å¯Ÿåˆ°ä»¥ä¸‹è¶‹åŠ¿ï¼š
1. ç¬¬ä¸€å­£åº¦é”€å”®é¢å‘ˆç°ç¨³æ­¥å¢é•¿
2. ç¬¬äºŒå­£åº¦å‡ºç°å°å¹…å›è½
3. ç¬¬ä¸‰ã€å››å­£åº¦æ¢å¤å¢é•¿æ€åŠ¿

ç”Ÿæˆçš„å¯è§†åŒ–å›¾è¡¨å·²å‡†å¤‡å°±ç»ªï¼Œæ‚¨å¯ä»¥é€šè¿‡é“¾æ¥ä¸‹è½½æŸ¥çœ‹ã€‚
è¿™ä¸æ˜¯çœŸå®çš„vllmæœåŠ¡ï¼Œä»…ç”¨äºæµ‹è¯•è¿é€šæ€§
This is not a real vLLM service; it is only used for connectivity testing."""

# ç”Ÿæˆçš„æ–‡ä»¶ä¿¡æ¯
GENERATED_FILES = [
    {
        "name": "sales_trend.png",
        "url": "http://localhost:8100/generated/sales_trend.png"
    }
]

class VLLMHandler(http.server.BaseHTTPRequestHandler):
    # ç¦ç”¨é»˜è®¤æ—¥å¿—
    def log_message(self, format, *args):
        return

    def _send_sse_response(self):
        """å‘é€é€å­—æµå¼çš„SSEå“åº”ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼‰"""
        # è®¾ç½®SSEæ ‡å‡†å“åº”å¤´
        self.send_response(200)
        self.send_header("Content-Type", "text/event-stream; charset=utf-8")
        self.send_header("Cache-Control", "no-cache")
        self.send_header("Connection", "keep-alive")
        self.end_headers()

        # å›ºå®šå“åº”å‚æ•°
        chunk_id = f"chatcmpl-{int(time.time() * 1000)}"
        created_time = int(time.time())
        model = "DeepAnalyze-8B"

        # æ ¸å¿ƒä¿®æ”¹ï¼šå°†å®Œæ•´æ–‡æœ¬æ‹†åˆ†ä¸ºå•ä¸ªå­—ç¬¦ï¼ˆé€å­—è¾“å‡ºï¼‰
        char_list = list(FULL_RESPONSE_TEXT)
        for char in char_list:
            chunk = {
                "id": chunk_id,
                "object": "chat.completion.chunk",
                "created": created_time,
                "model": model,
                "choices": [
                    {
                        "index": 0,
                        "delta": {"content": char},  # æ¯æ¬¡ä»…è¿”å›ä¸€ä¸ªå­—ç¬¦
                        "finish_reason": None
                    }
                ]
            }
            # SSEæ ¼å¼ï¼šdata: {json}\n\n
            sse_line = f"data: {json.dumps(chunk, ensure_ascii=False)}\n\n"
            self.wfile.write(sse_line.encode("utf-8"))
            self.wfile.flush()
            time.sleep(0.05)  # é€å­—é—´éš”ï¼ˆå¯è°ƒæ•´ï¼š0.05ç§’/å­—ï¼Œæ›´æµç•…ï¼‰

        # å‘é€ç»“æŸå—
        final_chunk = {
            "id": chunk_id,
            "object": "chat.completion.chunk",
            "created": created_time,
            "model": model,
            "choices": [
                {
                    "index": 0,
                    "delta": {},
                    "finish_reason": "stop"
                }
            ],
            "generated_files": GENERATED_FILES
        }
        final_sse_line = f"data: {json.dumps(final_chunk, ensure_ascii=False)}\n\n"
        self.wfile.write(final_sse_line.encode("utf-8"))
        self.wfile.flush()

        # å‘é€SSEç»“æŸæ ‡å¿—
        self.wfile.write(b"data: [DONE]\n\n")
        self.wfile.flush()

    def _send_json_response(self, status_code: int, content: Dict[str, Any]):
        """å‘é€éæµå¼JSONå“åº”"""
        self.send_response(status_code)
        self.send_header("Content-Type", "application/json; charset=utf-8")
        self.end_headers()
        self.wfile.write(json.dumps(content, ensure_ascii=False).encode("utf-8"))

    def do_POST(self) -> None:
        """å¤„ç†POSTè¯·æ±‚"""
        if self.path == "/v1/chat/completions":
            try:
                content_length = int(self.headers.get('Content-Length', 0))
                request_body = self.rfile.read(content_length).decode('utf-8')
                request_data = json.loads(request_body)
                stream = request_data.get('stream', False)

                if stream:
                    self._send_sse_response()
                else:
                    # éæµå¼è¿”å›å®Œæ•´æ–‡æœ¬
                    full_response = {
                        "id": f"chatcmpl-{int(time.time() * 1000)}",
                        "object": "chat.completion",
                        "created": int(time.time()),
                        "model": "DeepAnalyze-8B",
                        "choices": [
                            {
                                "index": 0,
                                "message": {
                                    "role": "assistant",
                                    "content": FULL_RESPONSE_TEXT,
                                    "files": GENERATED_FILES
                                },
                                "finish_reason": "stop"
                            }
                        ],
                        "generated_files": GENERATED_FILES
                    }
                    self._send_json_response(200, full_response)

            except Exception as e:
                self._send_json_response(500, {"error": str(e)})

        elif self.path == "/v1/models":
            models_response = {
                "object": "list",
                "data": [
                    {
                        "id": "DeepAnalyze-8B",
                        "object": "model",
                        "created": int(time.time()),
                        "owned_by": "deepanalyze"
                    }
                ]
            }
            self._send_json_response(200, models_response)

        else:
            self._send_json_response(404, {"error": "Endpoint not found"})

    def do_GET(self) -> None:
        """å¤„ç†GETè¯·æ±‚"""
        if self.path == "/health":
            self._send_json_response(200, {"status": "healthy", "timestamp": int(time.time())})
        elif self.path == "/v1/models":
            self.do_POST()
        else:
            self._send_json_response(404, {"error": "Endpoint not found"})

def run_server(host: str = "0.0.0.0", port: int = 8000) -> None:
    """å¯åŠ¨æ¨¡æ‹ŸvLLMæœåŠ¡å™¨"""
    server = http.server.ThreadingHTTPServer((host, port), VLLMHandler)
    print(f"âœ… æ¨¡æ‹ŸvLLMæœåŠ¡å™¨å¯åŠ¨æˆåŠŸï¼ˆé€å­—æµå¼è¾“å‡ºï¼‰")
    print(f"   - åœ°å€: http://{host}:{port}")
    print(f"   - é€å­—é—´éš”: 0.05ç§’/å­—ç¬¦ï¼ˆå¯ä¿®æ”¹time.sleepå€¼è°ƒæ•´ï¼‰")
    print(f"   - æŒ‰ Ctrl+C åœæ­¢æœåŠ¡å™¨\n")
    
    try:
        server.serve_forever()
    except KeyboardInterrupt:
        print("\nğŸ›‘ æœåŠ¡å™¨æ­£åœ¨åœæ­¢...")
        server.shutdown()
        server.server_close()
        print("âœ… æœåŠ¡å™¨å·²åœæ­¢")

if __name__ == "__main__":
    run_server(host="0.0.0.0", port=8000)